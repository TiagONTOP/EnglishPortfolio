{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87976e75-c792-473d-939e-f79b97853e25",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to this notebook where we will explore a fascinating aspect of deep learning - automatic text generation. The goal of this project is to train a neural network model to generate text that resembles the works of William Shakespeare, one of the most iconic writers in history.\n",
    "\n",
    "To achieve this, we will use a neural network architecture called Long Short-Term Memory (LSTM). LSTMs are a special subcategory of recurrent neural networks (RNNs) that are particularly effective at learning from long sequences of data, such as sentences or paragraphs, making them well-suited for tasks like text generation.\n",
    "\n",
    "To train our model, we will use a corpus of Shakespeare's texts. This corpus will serve as the training data for our LSTM, allowing it to learn the \"style\" of Shakespeare's writing. Once trained, the model will be capable of generating new sentences inspired by what it has learned from this corpus.\n",
    "\n",
    "It's important to note that the text generated by our model will not be genuine Shakespeare; it won't have the same depth or meaning. However, it should exhibit stylistic similarities, such as similar sentence structures, vocabulary, and grammatical patterns commonly found in Shakespeare's works.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- Prepare and preprocess our corpus of texts.\n",
    "- Build our LSTM model using Keras, a popular Python library for deep learning.\n",
    "- Train this model on our corpus.\n",
    "- Generate new texts from the trained model.\n",
    "\n",
    "It's an exciting journey at the intersection of literature and artificial intelligence. So let's dive in and see what our machine can create!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52b49b-2aae-47d0-8f01-28e6140d49f0",
   "metadata": {},
   "source": [
    "# Data Preparation and Preprocessing\n",
    "\n",
    "In this code block, we start by importing the necessary libraries for our project. This includes `random`, `numpy`, and several sub-libraries of `tensorflow` that we need to build and train our LSTM model.\n",
    "\n",
    "Next, we use the `get_file` function from `tensorflow.keras.utils` to download the text file 'shakespeare.txt' that contains our corpus. This file is read, decoded as 'utf-8', converted to lowercase to normalize the text, and we replace line breaks with spaces to facilitate further processing.\n",
    "\n",
    "After that, we prepare several data structures that will help us transform our text into usable inputs for our LSTM model:\n",
    "\n",
    "- `characters`: a list of all unique characters in our text, sorted in alphabetical order. This will serve to build our \"vocabulary\" for the model.\n",
    "- `char_to_index` and `index_to_char`: two dictionaries that allow us to convert between characters and numeric indices. This is necessary because our LSTM model does not directly process characters but the numeric indices representing them.\n",
    "\n",
    "We also define two hyperparameters for our data preparation: `SEQ_LENGTH` and `STEP_SIZE`. `SEQ_LENGTH` determines the length of each input sequence for our model, and `STEP_SIZE` determines the spacing between these sequences. In other words, for every `STEP_SIZE` characters in our text, we prepare an input sequence of length `SEQ_LENGTH`.\n",
    "\n",
    "Next, we prepare our inputs and targets for the LSTM model. The inputs are sequences of `SEQ_LENGTH` characters from our text, and the targets are the characters directly following these sequences.\n",
    "\n",
    "Finally, we transform these sequences and targets into \"one-hot\" representations. This is a common technique in deep learning to handle categorical data, such as our characters. Each character is represented by a vector of the length of our \"vocabulary,\" where all positions are zero except the one corresponding to that character, which is one. Thus, `x` and `y` are three-dimensional and two-dimensional matrices, respectively, where each row represents an input sequence or target, and each column corresponds to a character in our \"vocabulary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcad507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c562d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74afd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'rb') as file:\n",
    "    text = file.read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a33097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8082f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e48015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 200\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82ab21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee39784",
   "metadata": {},
   "source": [
    "# LSTM Model Construction and Text Generation\n",
    "\n",
    "In this code block, we start by building our LSTM model using the Keras `Sequential` API. Our model consists of three layers:\n",
    "\n",
    "1. An LSTM layer with 128 units. This layer will do the bulk of the work in learning the sequences from our text.\n",
    "2. A `Dense` layer (i.e., a fully connected layer) with as many units as we have unique characters in our text. This layer is responsible for converting the outputs from our LSTM layer into predictions for the next character to generate.\n",
    "3. An `Activation` layer that applies the \"softmax\" activation function. This function converts the scores from the Dense layer into probabilities for each possible character.\n",
    "\n",
    "After defining the architecture of our model, we compile it with the `categorical_crossentropy` loss function (suited for our multiclass classification problem) and the RMSprop optimizer. Then, we train the model on our prepared training data with a `batch_size` of 256 for 4 epochs.\n",
    "\n",
    "Next, we define two functions to generate text from our trained model:\n",
    "\n",
    "1. `sample`: This function takes an array of predictions from our model (a score for each possible character) and a \"temperature\" that controls the diversity of the generated text. A higher temperature gives more random and diverse text, while a lower temperature gives more predictable text. The function uses these scores to generate a probability distribution and then samples from that distribution to choose the next character.\n",
    "\n",
    "2. `generate_text`: This function generates a sequence of text of a given length using our trained model and the `sample` function. It starts by randomly choosing a starting sequence from our original text and then generates one character at a time, updating the input sequence at each step.\n",
    "\n",
    "Finally, we generate and display a sequence of 20 characters from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7017fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb68a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftiag\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1453/1453 [==============================] - 46s 26ms/step - loss: 1.8373\n",
      "Epoch 2/4\n",
      "1453/1453 [==============================] - 37s 26ms/step - loss: 1.5341\n",
      "Epoch 3/4\n",
      "1453/1453 [==============================] - 38s 26ms/step - loss: 1.4665\n",
      "Epoch 4/4\n",
      "1453/1453 [==============================] - 39s 27ms/step - loss: 1.4316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a78f08dcd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd881d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6a9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lenght, temperature):\n",
    "    # Initialise aléatoirement un numero d'index dans le text\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    # Initialise le texte predit\n",
    "    generated = ''\n",
    "    # Initialise la phrase selectionnée dans le texte\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    # Ajoute la phrase au texte de sortie\n",
    "    generated += sentence\n",
    "    # La boucle parcourt de 0 à \"lenght\" puis une autre boucle parcour la phrase pour initialisé \"x_predictions\",\n",
    "    # ensuite pour tout i on calcule les preds puis on utilise la fonction \"sample\" qui renvoie l'index du caractère\n",
    "    # à la fin on prends le caractère puis on l'ajoute à generated et enfin on actualise la phrase.\n",
    "    for i in range(lenght):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "        \n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "        \n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2122f06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' thy friends are fled to wait upon thy foes, and crossly to thy good all fortune goes.  henry bolingbroke: bring forth these men. bushy and green, i will not vex your souls-- since presently your soul so the heart to the'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(20, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
